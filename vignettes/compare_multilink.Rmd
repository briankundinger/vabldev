---
title: "multilink"
output: html_document
date: "2024-03-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::load_all()
library(janitor)
library(multilink)
library(readr)
library(stringr)
```

## Compare with multilink

We modify one of the Sadinle simulation files, introducing duplications in both datasets. 

```{r}
i = 256
all_patterns <- F
S = 1000 # Small S just to make things run faster 
burn = S * .1
m_prior <- u_prior <- alpha <- beta <- 1
files <- list.files(path = "../data/sadinle_sim_data/", full.names = T)

overlap <- 50

records <- read_csv(files[i], col_types = cols())
records$file <- rep(2:1, length.out = dim(records)[1])

records <- records %>%
  janitor::clean_names() %>%
  mutate(rec_id = as.numeric(str_extract(rec_id, "\\d{3}")) + 1)

n1 <- 500
n2 <- 500

file1 <- records %>%
  filter(file ==1,
         rec_id <= n1) %>%
  as.matrix(.) %>%
  data.frame(.) %>%
  mutate(occup = as.numeric(occup))

file2 <- records %>%
  filter(file == 2,
         rec_id %in% c(1:overlap, (n1 +1):(1000 - overlap))) %>%
  as.matrix() %>%
  data.frame(.) %>%
  mutate(occup = as.numeric(occup))

copy_index <- 1:overlap
paste_index <- (overlap +1):(2*overlap)

# file1[paste_index, ] <- file1[copy_index, ]
# 
# Ztrue_pairs <- data.frame(id_1 = 1:(2*overlap),
#                           id_2 = rep(1:overlap, 2))

# %>%
#   arrange(id_2)

file1[paste_index, ] <- file1[copy_index, ]
file2[paste_index, ] <- file2[copy_index, ]

Ztrue_pairs <- data.frame(id_1 = rep(1:(2*overlap), 2),
                          id_2 = c(rep(1:overlap, 2), 
                                   rep(1:overlap, 2) + overlap)) %>%
  arrange(id_2)


# copy_index <- 1:(overlap/2)
# paste_index <- (overlap +1):(overlap + overlap/2)
# 
# Ztrue_pairs <- data.frame(id_1 = 1:(overlap + overlap/2), 
#                           id_2 = c(rep(1:(overlap/2), 2), ((overlap/2)+1):overlap)) %>% 
#   arrange(id_2)



# cd <- compare_records(file1, file2, c(2, 3, 5, 6) + 1,
#                         types = c("lv", "lv", "bi", "bi"))

cd <- compare_records(file1, file2, c(2, 3, 4, 5, 6) + 1,
                        types = c("lv", "lv", "bi", "bi", "bi"))

hash <- hash_comparisons(cd)
```



# Multiple Match Approach

In this setting, the multiple match approach seems to work well. 

```{r}

# out_mm <- fabl_mm(hash, S = S, burn = burn)
# result_mm <- estimate_links_mm(out_mm, hash, resolve = T)
# Z_hat <- cbind(result_mm$Z_hat$target_id, result_mm$Z_hat$base_id)
# evaluate_links(Z_hat, Ztrue_pairs, n1, "pairs")

out_mm <- fabl_mm(hash, S = S, burn = burn, max_K = 10)
result_mm <- estimate_links_mm(out_mm, hash, resolve = F)
Z_hat <- cbind(result_mm$Z_hat$target_id, result_mm$Z_hat$base_id)
evaluate_links(Z_hat, Ztrue_pairs, n1, "pairs")

# out_mm <- fabl_mm(hash, S = S, burn = burn, max_K = 2)
# result_mm <- estimate_links_mm(out_mm, hash, resolve = T)
# Z_hat <- cbind(result_mm$Z_hat$target_id, result_mm$Z_hat$base_id)
# evaluate_links(Z_hat, Ztrue_pairs, n1, "pairs")


result_mm <- get_mms(out_mm, hash)
Z_hat <- cbind(result_mm$Z_hat$target_id, result_mm$Z_hat$base_id)
evaluate_links(Z_hat, Ztrue_pairs, n1, "pairs")


# out <- fabl(hash, S = S, burn = burn)
# result <- estimate_links(out, hash, resolve = F)
# Z_hat <- make_Zhat_pairs(result$Z_hat)
# evaluate_links(Z_hat, Ztrue_pairs, n1, "pairs")

```
# Variational Fastlink

```{r}
out_fl <- variational_fastlink(hash, tmax = 10000)
estimate_fl <- estimate_links_fl(out_fl, hash)
Z_hat <- data.frame(id_1 = estimate_fl$fs_linkages$a,
                    id_2 = estimate_fl$fs_linkages$b)
evaluate_links(Z_hat, Ztrue_pairs, n1, "pairs")
```



# Multilink

Very sensitive to "maximum cluster size" parameter.
```{r}

all_records <- rbind(file1, file2)[, c(2, 3, 5, 6) + 1]
all_records$occup <- as.character(all_records$occup)
cd_multilink <- multilink::create_comparison_data(all_records, 
                                  types = c("lv", "lv", "bi", "bi"), 
                                  breaks = list(c(0, .25, .5), 
                                                c(0, .25, .5), 
                                                NA, 
                                                NA), 
                                  file_sizes = c(n1, n2), 
                                  duplicates = c(1, 0), 
                                  verbose = T)
prior <- multilink::specify_prior(cd_multilink, NA, NA, 0,
                                  NA, c(2, 1), NA, list(1, 1), NA, NA)

chain_multilink <- multilink::gibbs_sampler(cd_multilink, prior, n_iter = S)
result_ML <- multilink::find_bayes_estimate(chain_multilink$partitions, burn)

cluster_labels <- unique(result_ML)

df_1_clusters <- result_ML[1:500]
df_2_clusters <- result_ML[501:1000]

Z_list <- list()

for(x in cluster_labels){
  match1 <- which(df_1_clusters == x)
  match2 <- which(df_2_clusters == x)
  
  if(length(match1) == 0 ||length(match2) == 0){
    next
  }
  Z_list[[x]] <- data.frame(id_1 = match1, 
             id_2 = match2)
}

Z_hat <- do.call(rbind, Z_list)

evaluate_links(Z_hat, Ztrue_pairs, n1, "pairs")

```

# Standard fabl

If there are multiple matches in the target file ($X_1$) for a single record in the base file ($X_2)$, fabl will struggle to find matches. In the best case scenario, the one record will have posterior probability 0.51, and the other will have 0.49, and the algorithm will randomly declare one a match through the Bayes estimate. If there are more than two matches, then the probability will likely be too dispersed for the Bayes estimate to identify any as matches. 

```{r}
out <- fabl(hash, S = S, burn = burn)
result <- estimate_links(out, hash, resolve = F)
result$Z_hat
```

```{r}
hash <- readRDS("../../multiple_match/out/ncvr/combine/hash")
S = 3
burn = 1
chain <- fabl_mm(hash, S = S, burn = burn, max_K = 3)
results <- estimate_links_mm(chain, hash)

out_vabl <- vabl(hash)
out_vabl$a_pi

out_vabl <- variational_fastlink(hash, tmax = 1000)
out_vabl$a_pi
```

